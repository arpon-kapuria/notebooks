{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNpwP2OCmfPlkzE085gsUkn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"q68_buinuceb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","import torch\n","import rtdl\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score\n","from imblearn.over_sampling import SMOTE\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","from sklearn.utils.class_weight import compute_class_weight"],"metadata":{"id":"m5QVduytuVTF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Data\n","df = pd.read_csv(\"/content/drive/MyDrive/AMIRL Task/AQI/final-data-with-label.csv\")\n","\n","df.head()"],"metadata":{"id":"S1oWWJHLuXqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select Features & Target\n","X = df.drop(['date', 'address', 'AQI', 'AQI Category', 'day_of_year'], axis=1)\n","y = df['AQI Category']\n","\n","# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","\n","X_train.shape"],"metadata":{"id":"TSk7mHESupPK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"id":"KoReFkOFvKnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNb2U-gNs8tL"},"outputs":[],"source":["# Normalize Numerical Features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Compute class weights dynamically\n","classes = list(set(y_train))\n","class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n","class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n","\n","# Convert to tensor for PyTorch loss function\n","class_weights_tensor = torch.tensor([class_weights[i] for i in sorted(class_weights.keys())], dtype=torch.float32)\n","\n","# Handle Class Imbalance (SMOTE)\n","smote = SMOTE(random_state=42)\n","X_train, y_train = smote.fit_resample(X_train, y_train)\n","\n","# Convert Data to Tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Create DataLoaders\n","batch_size = 64\n","train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n","\n","# Define FT-Transformer Model\n","model = rtdl.FTTransformer.make_default(\n","    n_num_features=X.shape[1],\n","    cat_cardinalities=None,\n","    d_out=len(np.unique(y))\n",")\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"\\nRunning code on {Device}\")\n","\n","# Define Loss Function with Class Weights\n","class_weights_tensor = class_weights_tensor.to(device)\n","criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Training Loop with Metrics Tracking\n","model.to(device)\n","\n","# Training Loop with Progress Bar\n","num_epochs = 20\n","train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_train_loss, correct_train, total_train = 0, 0, 0\n","\n","    # Training\n","    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as tepoch:\n","        for X_batch, y_batch in tepoch:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_train_loss += loss.item()\n","            correct_train += (outputs.argmax(1) == y_batch).sum().item()\n","            total_train += y_batch.size(0)\n","\n","            tepoch.set_postfix(loss=loss.item())\n","\n","    train_loss = total_train_loss / len(train_loader)\n","    train_acc = correct_train / total_train\n","\n","    # Evaluate on Test Data\n","    model.eval()\n","    total_test_loss, correct_test, total_test = 0, 0, 0\n","\n","    with torch.no_grad():\n","        for X_batch, y_batch in test_loader:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","\n","            total_test_loss += loss.item()\n","            correct_test += (outputs.argmax(1) == y_batch).sum().item()\n","            total_test += y_batch.size(0)\n","\n","    test_loss = total_test_loss / len(test_loader)\n","    test_acc = correct_test / total_test\n","\n","    # Store Metrics\n","    train_losses.append(train_loss)\n","    test_losses.append(test_loss)\n","    train_accuracies.append(train_acc)\n","    test_accuracies.append(test_acc)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}] â†’ Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n","\n","\n","# Plot Training Curves\n","plt.figure(figsize=(12, 5))\n","\n","# Plot Loss\n","plt.subplot(1, 2, 1)\n","plt.plot(range(1, num_epochs+1), train_losses, label=\"Train Loss\", marker=\"o\")\n","plt.plot(range(1, num_epochs+1), test_losses, label=\"Test Loss\", marker=\"s\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training & Testing Loss\")\n","plt.legend()\n","plt.grid()\n","\n","# Plot Accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(range(1, num_epochs+1), train_accuracies, label=\"Train Accuracy\", marker=\"o\")\n","plt.plot(range(1, num_epochs+1), test_accuracies, label=\"Test Accuracy\", marker=\"s\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Training & Testing Accuracy\")\n","plt.legend()\n","plt.grid()\n","\n","plt.show()\n","\n","# Final Evaluation\n","model.eval()\n","y_pred_list, y_true_list = [], []\n","\n","with torch.no_grad():\n","    for X_batch, y_batch in test_loader:\n","        X_batch = X_batch.to(device)\n","        outputs = model(X_batch)\n","        _, y_pred = torch.max(outputs, 1)\n","        y_pred_list.extend(y_pred.cpu().numpy())\n","        y_true_list.extend(y_batch.numpy())\n","\n","# Compute Final Metrics\n","balanced_acc = balanced_accuracy_score(y_true_list, y_pred_list)\n","print(\"\\nFinal Balanced Accuracy:\", balanced_acc)\n","print(\"\\nClassification Report:\\n\", classification_report(y_true_list, y_pred_list))\n"]},{"cell_type":"code","source":[],"metadata":{"id":"j70R-JcIvmVw"},"execution_count":null,"outputs":[]}]}